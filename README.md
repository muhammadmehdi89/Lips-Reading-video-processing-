# Lips-Reading-video-processing-
Overview
This project implements a lip reading system using a combination of Convolutional Neural Networks (CNNs) using conv3d(because video is 3d data) for visual feature extraction from videos and converting it into frames to learn patterns of lips and Recurrent Neural Networks (RNNs)/Long-Short Term Memory (LSTM)  for sequential processing and decoding of lip movements into textual transcriptions. The goal is to recognize spoken words from lip movements captured in video sequences.

Requirements
Python 3.x
TensorFlow (or any deep learning framework of your choice)
OpenCV (for video processing)
Numpy
Matplotlib (for visualization)

Lipnet architecture:

![image](https://github.com/muhammadmehdi89/Lips-Reading-video-processing-using-keras/assets/142395586/a40a3659-9244-4936-91ec-16ec3a85eb44)
